- [#A] #GeoWhale Ideas
  collapsed:: true
  - GeoWhale debería ser una aplicación local Python (no Docker) que lanzara Dockers a demanda para realizar operaciones atómicas. Por ejemplo:
    ```shell
    #!/bin/bash
    
    # Define the source and destination PostgreSQL connections
    src_conn="PG:host=${KERDES_PG_HOST} port=${KERDES_PG_PORT} dbname=data user=${KERDES_PG_USER} password=${KERDES_PG_PASS}"
    dst_conn="PG:host=${KEPLER_PG_HOST} port=${KEPLER_PG_PORT} dbname=cell_raw_data user=${KEPLER_PG_USER} password=${KEPLER_PG_PASS}"
    
    # Define the source and destination tables
    src_table="dat_oferta_turistica.grid_250"
    dst_schema="context"
    dst_table="${dst_schema}.grid_250_import"
    
    # Copy data
    ogr2ogr -f "PostgreSQL" -overwrite -progress \
      -nln ${dst_table} \
      "${dst_conn}" \
      "${src_conn}" \
      ${src_table}
    
    # Transform
    PGPASSWORD=$KEPLER_PG_PASS psql \
      -h ${KEPLER_PG_HOST} \
      -p ${KEPLER_PG_PORT} \
      -U ${KEPLER_PG_USER} \
      -d cell_raw_data \
      -f 020-etl-grid_250.sql
    ```
  - Esto es muy verbose, estaría bien que fuera algo similar a esto:
    ```shell
    #!/bin/bash
    
    gw_pgtopg [ HOST A ] [ HOST B ] -s [ SOURCE DB.SOURCE TABLE ] -d [ DESTINATION DB.DESTINATION TABLE ]
    
    gw_pgtopg [ HOST A ] [ HOST B ] -d [ DESTINATION DB.DESTINATION TABLE ] --sql [ SQL or file ]
    
    gw_pgrun [ HOST A ] -d [ DESTINATION DB ] --sql [ SQL ] file
    ```
  - Con un almacén centralizado de orígenes de datos para definir HOST X, estos programas compondrían la sintaxis de los anteriores comandos y lanzarían un contenedor efímero GRASS para lanzarlo